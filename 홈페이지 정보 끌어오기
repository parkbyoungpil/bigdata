from bs4 import BeautifulSoup
import urllib.request
import pandas as pd
import datetime


def hollys_store():
    result = []
    for page in range(1, 10):
        Hollys_url = f'https://www.hollys.co.kr/store/korea/korStore2.do?pageNo={page}&sido=&gugun=&store='
        print(f'[INFO] 크롤링 중: {Hollys_url}')
        html = urllib.request.urlopen(Hollys_url)
        soup = BeautifulSoup(html, 'html.parser')
        tag_tbody = soup.find('tbody')

        if not tag_tbody:
            continue

        for store in tag_tbody.find_all('tr'):
            store_td = store.find_all('td')
            if len(store_td) <= 3:
                break

            store_name = store_td[1].string
            store_sido = store_td[0].string
            store_address = store_td[3].string
            store_phone = store_td[5].string

            result.append([store_name, store_sido, store_address, store_phone])

    return result


# 실행 및 저장
store_data = hollys_store()
columns = ['매장명', '시도', '주소', '전화번호']
df = pd.DataFrame(store_data, columns=columns)

now = datetime.datetime.now()
df.to_csv(f'hollys_store_{now:%Y%m%d}.csv', encoding='utf-8-sig', index=False)
print('[완료] CSV 파일 저장 완료')
